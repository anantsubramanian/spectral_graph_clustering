{
  "name": "Spectral graph clustering",
  "tagline": "",
  "body": "## Summary\r\nWe intend to implement a hybrid MPI + CUDA algorithm to perform spectral clustering of an input graph. We will test the algorithm against a sequential MATLAB implementation and a parallel single-GPU CUDA implementation using one (or more) of the SNAP data sets on two fronts: quality and overall computation time. We may use more precise measurements to support our claims and verify our hypotheses.\r\n\r\n## Resources\r\nWe will be using a couple of papers to help us get familiar with the mathematical theory of spectral clustering, as well as sequential implementations of the same. We would also be referring to previous (non-hybrid) parallel implementations of parts of the algorithm, such as graph construction and eigen value computation. We have outlined these below.\r\n\r\n##Plan to Achieve\r\n\r\nWe will have a working, correct implementation of a C++ hybrid MPI + CUDA parallel version of a Spectral Clustering algorithm as a miniature library. We expect the quality of the results produced by our algorithm to be comparable \\footnote{If we do decide to trade quality for speedup, we will make sure to document and bound the error in our algorithm.} to those produced by a sequential version of the algorithm.\r\n\r\nThe previous CUDA-only implementation \\cite{418project} achieved \\textbf{5x} speedup over a sequential MATLAB version. Pessimistically, we expect to achieve at least \\textbf{5x} speedup over the sequential MATLAB version as well, but on larger data sets (as we have more total memory and compute power available to us).\r\n\r\nWe will also compare our code with MPI-only (if available) and CUDA-only parallel implementations of the algorithm, and hope to stay competitive.  We anticipate two major bottlenecks in our code: inter-node communication overhead in MPI and CUDA host memory to device memory transfer overhead. We will spend a significant amount of time optimizing and analyzing these two.\r\n\r\nFor the poster session, we will show a visualization of our speedup graphs, and discuss the parallelization approaches and trade-offs that we made. We will also show the interface to the library, the API structure and the easy of use of our code.\r\n\r\n#Hope to Achieve\r\n\r\nWe hope to achieve at least \\textbf{(5 + 0.5 * number of nodes)x} speedup on two data sets. The reason is that we expect the algorithm to scale with the number of nodes as well, providing more speedup than the \\textbf{5x} speedup obtained using the CUDA-only implementation. However, we anticipate non-ideal speedup and limit ourselves to a more achievable goal of 0.5 * number of nodes.\r\n\r\nFurther, if our project goes better than expected, we will test against a few more data sets (with varying degrees of sparsity) and study the scaling characteristics of our code on these data sets. In the best case scenario, we would also perform isolated testing on AWS machines or on different GPUs to analyze the variability in our results.\r\n\r\n###In Case of Delays\r\n\r\nConversely, if our project does not go according to the time line due to unforeseen issues, we will implement a subpart of the algorithm completely and correctly, and describe exactly what extra work would need to be done to convert the partial results into the final expected result.\r\n\r\nIf our speedups are not as we expected, we will study the scaling properties of various parts of the algorithm individually and point out exactly why our algorithm does not work as we expected.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}